{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata\n",
    "- Link to website: https://www.imdb.com/search/title/?title_type=feature&year=1950-01-01,2012-12-31&sort=alpha,asc\n",
    "- how to get source code of website in python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## can you scrap forums on hello iitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from tqdm import tqdm_notebook as tn\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keep in mind this link is alphabatically sorted or whaterver see yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status is green ðŸ’š\n",
      "Carefull: each page will take about 5 seconds to process\n",
      "How many pages do you want to process? 2\n",
      "ETA: 10 seconds.\n",
      "1 )   Page No. -->  1  <-- is being processed ...\n",
      "Completed in ðŸ‘‰ 9.5 seconds.\n",
      "2 )   Page No. -->  2  <-- is being processed ...\n",
      "Completed in ðŸ‘‰ 11.1 seconds.\n",
      "ðŸ‘‰ It took us 20.6 seconds, to process your request of processing 2 pages from IMDB webpage. ðŸ‘ˆ\n"
     ]
    }
   ],
   "source": [
    "web_link='https://www.imdb.com/search/title/?title_type=feature&year=1950-01-01,2012-12-31&sort=boxoffice_gross_us,asc'\n",
    "imdb_data=requests.get(web_link)\n",
    "if imdb_data.status_code==200:\n",
    "    print(\"Status is green ðŸ’š\")\n",
    "else:\n",
    "    print(\"Status is red ðŸŽ\")\n",
    "\n",
    "soup=bs(imdb_data.text,features='html.parser')\n",
    "#print(soup.prettify())\n",
    "\n",
    "# getting this donw\n",
    "film_name=[] #done\n",
    "film_image_link=[] #done\n",
    "film_link=[] #done\n",
    "film_rating=[] #done\n",
    "film_votes=[] #done\n",
    "film_gross_income=[] #done\n",
    "film_director=[]\n",
    "film_cast=[]\n",
    "film_metascore=[] #done\n",
    "release_year=[] #done\n",
    "film_length=[] #done\n",
    "film_geners=[] #done\n",
    "\n",
    "print('Carefull: each page will take about 5 seconds to process')\n",
    "how_many_pages=input('How many pages do you want to process? ')\n",
    "print('ETA:',5*int(how_many_pages),'seconds.')\n",
    "\n",
    "time1=time.time()\n",
    "\n",
    "page_counter=0\n",
    "while(soup.find_all('div',{'class':'desc'})[0].find('a',{'class':'lister-page-next next-page'})!=None and page_counter<int(how_many_pages)):\n",
    "    start_time=time.time()\n",
    "    print(page_counter+1,')   Page No. --> ',str(page_counter+1),' <-- is being processed ...') #to keep track of loops\n",
    "    for link in soup.find_all('div',{'class':'lister-item mode-advanced'}):\n",
    "\n",
    "        # image link\n",
    "        film_image_link.append('https://www.imdb.com'+link.find('div',{'class':'lister-item-image float-left'}).a.get('href'))\n",
    "        foo1=link.find('div',{'class':'lister-item-content'})\n",
    "\n",
    "        # name, link, realease year\n",
    "        foo2=foo1.find('h3',{'class':'lister-item-header'})\n",
    "        film_link.append('https://www.imdb.com'+foo2.a.get('href')) #I am only adding imdb.com/ if link does not work edit it\n",
    "        film_name.append(foo2.a.contents[0].strip('\"'))\n",
    "        release_year.append(foo2.find('span' ,{'class':\"lister-item-year text-muted unbold\"}).string[1:5]) # to get rid of '(----)'\n",
    "\n",
    "        # metascore and imdb rating\n",
    "        if foo1.find('div',{'class':\"inline-block ratings-imdb-rating\"})!=None:\n",
    "            film_rating.append(float(foo1.find('div',{'class':\"inline-block ratings-imdb-rating\"}).strong.string))\n",
    "        else:\n",
    "            film_rating.append(np.nan)\n",
    "        #film_rating.append(float(foo1.find('div',{'class':\"inline-block ratings-imdb-rating\"}).strong.string)) # see if it works\n",
    "        if foo1.find('div',{'class':\"inline-block ratings-metascore\"})!=None:\n",
    "            film_metascore.append(foo1.find('div',{'class':\"inline-block ratings-metascore\"}).span.string)\n",
    "        else:\n",
    "            film_metascore.append(np.nan)\n",
    "\n",
    "        # length, geners\n",
    "        foo5=foo1.find('p',{'class':\"text-muted\"})\n",
    "        how_many_geners=len(foo5.contents)\n",
    "        if how_many_geners>1:\n",
    "            if foo5.find('span',{'class':'genre'})!=None:\n",
    "                if foo5.find('span',{'class':'runtime'})!=None:\n",
    "                    film_geners.append(foo5.find('span',{'class':'genre'}).string.strip())\n",
    "                    film_length.append(foo5.find('span',{'class':'runtime'}).string)\n",
    "                else:\n",
    "                    film_geners.append(foo5.find('span',{'class':'genre'}).string.strip())\n",
    "                    film_length.append(np.nan)\n",
    "            else:\n",
    "                film_geners.append('notFound')\n",
    "                film_length.append(np.nan)\n",
    "        else:\n",
    "            film_geners.append('notFound')\n",
    "            film_length.append(np.nan)\n",
    "\n",
    "        '''# director and cast\n",
    "        ## task is to define a func. that takes raw list and gives stars and direcctors \n",
    "        ## OR takes names without '\\n' and then gives stars and directors\n",
    "        foo4=foo1.find('p',{'class':\"\"})\n",
    "        how_many_stars=len(foo4.contents)\n",
    "        if how_many_stars>1:\n",
    "\n",
    "        else:\n",
    "            film_director.append('notFound')\n",
    "            film_cast.append('notFound')'''\n",
    "\n",
    "        # votes and gross boxoffice\n",
    "        ## check if votes are available or not\n",
    "        foo3=foo1.find('p',{'class':\"sort-num_votes-visible\"})\n",
    "        if foo3!=None:\n",
    "            ## check is gross income is there or not :::: but no need to check reverse IG\n",
    "            if len(foo1.find_all('span',{'name':'nv'}))>1:\n",
    "                film_votes.append(foo3.find_all('span',{'name':'nv'})[0].string)\n",
    "                film_gross_income.append(foo3.find_all('span',{'name':'nv'})[1].string)\n",
    "            else:\n",
    "                film_votes.append(foo3.find_all('span',{'name':'nv'})[0].string)\n",
    "                film_gross_income.append(np.nan)\n",
    "\n",
    "        else:\n",
    "            film_gross_income.append(np.nan)\n",
    "            film_votes.append(np.nan)\n",
    "            \n",
    "    next_page_link='https://www.imdb.com'+soup.find_all('div',{'class':'desc'})[0].find('a',{'class':'lister-page-next next-page'}).get('href')\n",
    "    imdb_data=requests.get(next_page_link)\n",
    "    soup=bs(imdb_data.text,features='html.parser')\n",
    "    page_counter+=1\n",
    "    \n",
    "    # to get how much time it takes\n",
    "    end_time=time.time()\n",
    "    time_taken=end_time-start_time\n",
    "    print('Completed in ðŸ‘‰',round(time_taken,1),'seconds.')# as the all are taking time in seconds ig\n",
    "    \n",
    "time2=time.time()\n",
    "print('ðŸ‘‰ It took us',round(time2-time1,1),'seconds, to process your request of processing', how_many_pages,'pages from IMDB webpage. ðŸ‘ˆ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df=pd.DataFrame({\n",
    "    'Name':film_name,\n",
    "    'Rating':film_rating,\n",
    "    'BoxOffice Collection':film_gross_income,\n",
    "    'Release Year':release_year,\n",
    "    'Votes':film_votes,\n",
    "    'Genres':film_geners,\n",
    "    'Runtime':film_length,\n",
    "    'Metascore':film_metascore,\n",
    "    'Page Link':film_link,\n",
    "    'Image Link':film_image_link\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                     0\n",
       "Rating                   4\n",
       "BoxOffice Collection     4\n",
       "Release Year             0\n",
       "Votes                    0\n",
       "Genres                   0\n",
       "Runtime                  6\n",
       "Metascore               66\n",
       "Page Link                0\n",
       "Image Link               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pointers:**\n",
    "- BoxOffice Collection is really not there in most of the case when movies are in alphabate order.\n",
    "- Also metasocre is NaN in most rows.\n",
    "- Basic point scrapping does give you data but it is also very bad data with lots of BS. specially in metascore and Gross Collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
