{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def idFinder(idList):\n",
    "    for id in idList:\n",
    "        if len(id)>4:\n",
    "            return id\n",
    "    # if not found\n",
    "    return 'noID'\n",
    "\n",
    "def get_bs(page_no):\n",
    "    r=requests.get('https://www.therugshopuk.co.uk/rugs-by-type/rugs.html?p='+str(page_no))\n",
    "    rugSoup=bs(r.text,features='html.parser')\n",
    "    return rugSoup\n",
    "\n",
    "def get_items(rugSoup):\n",
    "    items=[]\n",
    "    for item in rugSoup.find_all('li',{'class':'item product product-item'}):\n",
    "        try:\n",
    "            # just add another item that you want to scrap\n",
    "            miniItem={\n",
    "                'imageLink':item.img.get('src'),\n",
    "                'rugName':item.img.get('alt'),\n",
    "                'rugId':idFinder((item.find('div',{'class':'sku-bg'}).get_text()).split(' ')), # can modify bit with some function to get only neat ID no\n",
    "                'rugLink':item.find('a',{'class':'product photo product-item-photo'})['href'],\n",
    "                'rugPrice':item.find('span',{'class':'price'}).text\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print('Here we have this problem ------ %s'%e)\n",
    "            pass\n",
    "        items.append(miniItem)\n",
    "    return items"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_items=[]\n",
    "userPages=int(input('How many pages to scrape -->'))\n",
    "pagesToScrape=min(userPages,999)+1 # see how range() methos works\n",
    "for page in range(1,pagesToScrape): # as page number starts from 1\n",
    "    print('scrapping through page .... ',page)\n",
    "    currSoup=get_bs(page)\n",
    "    if not currSoup.find('div',{'class':'pages'}).find('a',{'class':'action next'}):\n",
    "        print('we have reached to the end')\n",
    "        break\n",
    "    else:\n",
    "        all_items.append(get_items(currSoup))\n",
    "    print('all asked pages scrapped')\n",
    "\n",
    "def flattner(totalList):\n",
    "    return [rugItem for pageItem in all_items for rugItem in pageItem]\n",
    "\n",
    "rugData=pd.DataFrame(flattner(all_items))\n",
    "#rugData.to_csv('rug-shop-uk.csv',index=False) #<------ uncomment to store into CSVb"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "20d64e6457634db286bb2f57e568cdcaaf14f5fbfe37d467c75a4a80d0f4d780"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}